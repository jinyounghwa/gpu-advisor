# GPU Advisor

**Planning-based AI Agent for GPU Purchase Timing**

A planning-based AI agent that decides optimal GPU purchase timing using AlphaZero/MuZero-style world model and Monte Carlo Tree Search (MCTS). The agent observes market data, simulates future scenarios, and recommends actions â€” mimicking how AlphaGo evaluates win rates in Go.

## ğŸ¯ Overview

This system helps answer the question: **"Should I buy this GPU now or wait?"**

Just like AlphaGo calculates win probabilities in Go, this system calculates **purchase profitability scores (0-100%)** to determine the best time to buy GPUs.

### ğŸ’¡ Project Motivation

As a researcher and developer, I found myself constantly facing the dilemma of GPU purchase timing. Graphics card prices fluctuate dramatically based on market conditions, new releases, and global supply chains. This project was born from a simple need: **to bring AI-powered decision intelligence to everyday purchase decisions**.

By applying the same Monte Carlo Tree Search (MCTS) principles that power AlphaGo to the GPU market, this system transforms complex market signals into actionable recommendations. This is part of my **"0.1B AI Project"** series - demonstrating that sophisticated AI applications don't always require billions of parameters, but rather smart architecture and thoughtful feature engineering.

### Key Features

- ğŸ¤– **AlphaZero Architecture**: 18.9M parameters (Representation, Dynamics, Prediction networks + MCTS)
- ğŸ“Š **Automated Data Collection**: Daily crawling of GPU prices, exchange rates, and news
- ğŸ§  **256-Dimensional Features**: Rich feature engineering from 11D to 256D
- ğŸ“ˆ **Real-time Predictions**: REST API for instant purchase timing recommendations
- â° **Cron Automation**: Fully automated daily data collection

### ğŸ® Core Principle: Game Theory Meets Market Analysis

The fundamental insight behind this project is simple yet powerful: **purchasing decisions can be modeled as a sequential decision-making game**, similar to Go.

**The Analogy:**
- In Go, AlphaGo evaluates "Should I play this move?" â†’ Win probability (0-100%)
- In GPU Market, our system evaluates "Should I buy this GPU?" â†’ Purchase profitability score (0-100%)

**How It Works:**
1. **State Representation**: Market conditions (prices, trends, news sentiment) are encoded into a 256-dimensional latent state
2. **MCTS Simulation**: The system simulates 50 possible future scenarios (price drops, new releases, market crashes)
3. **Value Prediction**: Each scenario is evaluated for purchase timing optimality
4. **Final Recommendation**: The best action (Buy Now / Wait) is selected based on simulated outcomes

Unlike traditional price prediction models that try to forecast exact future prices (which is nearly impossible), this system focuses on **decision quality** - answering "Is now a good time?" rather than "What will the price be?"

## ğŸ“‹ Architecture

```
Input: GPU Model (e.g., RTX 5060)
  â†“
AlphaZero MCTS Simulation
  â†“
Output: Purchase Score 75% â†’ "Buy Now!"
```

### System Components

1. **Data Collection System**
   - Danawa GPU price crawler (24 models)
   - Exchange rate fetcher (USD/KRW, JPY/KRW, EUR/KRW)
   - News crawler with sentiment analysis
   - 256-dimensional feature engineering

2. **AI Engine**
   - Representation Network (h): Encodes market state â†’ latent state
   - Dynamics Network (g): Predicts next state + reward
   - Prediction Network (f): Outputs policy + value
   - MCTS: Simulates future scenarios for optimal decisions

3. **Backend Server**
   - FastAPI REST API (`backend/simple_server.py`)
   - Real-time predictions
   - Training dashboard
   - Swagger UI documentation
   - Release/readiness pipeline on real crawled data

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.10+
pip install -r backend/requirements.txt
pip install -e ".[dev]"  # dev dependencies (pytest, httpx)
```

### Setup

1. **Configure Automated Data Collection**

```bash
./setup_cron.sh
```

This sets up daily automatic data collection at midnight (00:00).

2. **Manual Data Collection** (for testing)

```bash
python3 crawlers/run_daily.py
```

3. **Start Backend Server (Production Path)**

```bash
python3 backend/simple_server.py
```

Access the API at: `http://localhost:8000`
Swagger UI: `http://localhost:8000/docs`

### Docker (Alternative)

```bash
docker compose up --build
```

Backend: `http://localhost:8000` / Frontend: `http://localhost:3000`

### Running Tests

```bash
python3 -m pytest tests/ -v
```

### Production Auth & Persistence

`backend/simple_server.py` supports JWT auth (OAuth2 password flow), API key auth, hybrid mode, and pluggable DB backends.

```bash
# Auth mode: none | api_key | jwt | hybrid
export GPU_ADVISOR_AUTH_MODE=jwt
export GPU_ADVISOR_AUTH_DEFAULT_USER=admin
export GPU_ADVISOR_AUTH_DEFAULT_PASSWORD=change-me
export GPU_ADVISOR_JWT_SECRET='replace-with-long-random-secret'
export GPU_ADVISOR_JWT_EXP_SECONDS=3600

# Optional for api_key or hybrid mode
export GPU_ADVISOR_API_KEYS='key1,key2'

# Rate limit
export GPU_ADVISOR_RATE_LIMIT_PER_MINUTE=60

# Persistence backend: sqlite | postgres
export GPU_ADVISOR_DB_BACKEND=sqlite
export GPU_ADVISOR_DB_PATH='data/processed/gpu_advisor.db'
# If postgres:
# export GPU_ADVISOR_DB_BACKEND=postgres
# export GPU_ADVISOR_POSTGRES_DSN='postgresql://user:pass@localhost:5432/gpu_advisor'

# Sentiment backend: auto | transformers | rule
export GPU_ADVISOR_SENTIMENT_BACKEND=auto
export GPU_ADVISOR_SENTIMENT_MODEL='distilbert-base-uncased-finetuned-sst-2-english'
```

Token issuance endpoint:

```bash
curl -X POST http://localhost:8000/api/auth/token \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=admin&password=change-me"
```

### Making Predictions

```bash
curl -X POST http://localhost:8000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"model_name": "RTX 5060"}'
```

## ğŸ“Š Data Pipeline

```
Crawlers (Daily @ 00:00)
  â†“
Raw Data Collection
  â”œâ”€ GPU Prices (Danawa)
  â”œâ”€ Exchange Rates
  â””â”€ News + Sentiment
  â†“
Feature Engineering (11D â†’ 256D)
  â†“
Training Dataset
  â†“
AlphaZero Training
  â†“
Purchase Predictions
```

Operational note:
- Production data/agent path uses `crawlers/run_daily.py` + `backend/simple_server.py` + `backend/agent/*`.
- Legacy synthetic benchmark modules under `backend/main.py` and `backend/api/*` are not used for production decisions.

## ğŸ§  Feature Engineering (256 Dimensions)

| Feature Category | Dimensions | Description |
|-----------------|------------|-------------|
| Price Features | 60 | Normalization, volatility, moving averages |
| Exchange Features | 20 | USD/KRW, JPY/KRW, EUR/KRW trends |
| News Features | 30 | Sentiment analysis, keyword frequency |
| Market Features | 20 | Stock status, seller count |
| Time Features | 20 | Day of week, month, quarter |
| Technical Indicators | 106 | RSI, MACD, Bollinger Bands |

## ğŸ“ Project Structure

```
gpu-advisor/
â”œâ”€â”€ backend/                       # AI & API backend
â”‚   â”œâ”€â”€ simple_server.py           # FastAPI server
â”‚   â”œâ”€â”€ agent/                     # Agent pipeline
â”‚   â”‚   â”œâ”€â”€ gpu_purchase_agent.py  # MCTS planning agent
â”‚   â”‚   â”œâ”€â”€ fine_tuner.py          # Model fine-tuning
â”‚   â”‚   â”œâ”€â”€ evaluator.py           # Backtest evaluator
â”‚   â”‚   â””â”€â”€ release_pipeline.py    # Release quality gates
â”‚   â””â”€â”€ models/                    # AlphaZero networks
â”‚       â”œâ”€â”€ representation_network.py  # h(s): State encoder
â”‚       â”œâ”€â”€ dynamics_network.py        # g(s,a): World model
â”‚       â”œâ”€â”€ prediction_network.py      # f(s): Policy-value
â”‚       â””â”€â”€ mcts_engine.py             # MCTS tree search
â”‚
â”œâ”€â”€ crawlers/                      # Data collection modules
â”‚   â”œâ”€â”€ danawa_crawler.py          # GPU price crawler
â”‚   â”œâ”€â”€ exchange_rate_crawler.py   # Exchange rate fetcher
â”‚   â”œâ”€â”€ news_crawler.py            # News crawler
â”‚   â”œâ”€â”€ feature_engineer.py        # 256D feature generation
â”‚   â””â”€â”€ run_daily.py               # Daily orchestration
â”‚
â”œâ”€â”€ frontend/                      # Next.js React UI
â”‚   â””â”€â”€ app/page.tsx               # Advisor + Training dashboard
â”‚
â”œâ”€â”€ tests/                         # Pytest test suite
â”‚   â”œâ”€â”€ test_networks.py           # Neural network tests
â”‚   â”œâ”€â”€ test_mcts.py               # MCTS engine tests
â”‚   â”œâ”€â”€ test_feature_engineer.py   # Feature pipeline tests
â”‚   â””â”€â”€ test_api.py                # API endpoint tests
â”‚
â”œâ”€â”€ data/                          # Data storage
â”‚   â”œâ”€â”€ raw/                       # Raw collected data
â”‚   â””â”€â”€ processed/                 # 256D feature vectors
â”‚
â”œâ”€â”€ docs/                          # Technical documentation
â”œâ”€â”€ .github/workflows/ci.yml       # CI/CD pipeline
â”œâ”€â”€ Dockerfile                     # Backend container
â”œâ”€â”€ docker-compose.yml             # Multi-service orchestration
â”œâ”€â”€ pyproject.toml                 # Python project config
â””â”€â”€ .env.example                   # Environment template
```

## ğŸ“– Documentation

### Root Documents

- [`README.md`](README.md): í”„ë¡œì íŠ¸ ê°œìš”, ì•„í‚¤í…ì²˜, ì‹¤í–‰ ë°©ë²•, API ì‚¬ìš©ë²•
- [`ì¢…í•©_í”„ë¡œì íŠ¸_ë³´ê³ ì„œ.md`](ì¢…í•©_í”„ë¡œì íŠ¸_ë³´ê³ ì„œ.md): ì „ì²´ ì‹œìŠ¤í…œì„ í•œ ë²ˆì— ë³´ëŠ” í•œêµ­ì–´ ì¢…í•© ë³´ê³ ì„œ
- [`GPU_PURCHASE_ADVISOR_REPORT.md`](GPU_PURCHASE_ADVISOR_REPORT.md): ì„±ëŠ¥/í‰ê°€ ê²°ê³¼ ì¤‘ì‹¬ì˜ í•œêµ­ì–´ í‰ê°€ ë³´ê³ ì„œ
- [`CRAWLER_GUIDE.md`](CRAWLER_GUIDE.md): ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ë° cron ìš´ì˜ ê°€ì´ë“œ
- [`architecture_spec.md`](architecture_spec.md): AlphaZero/MuZero ê¸°ë°˜ íŠ¸ë ˆì´ë”© ì•„í‚¤í…ì²˜ ìƒì„¸ ëª…ì„¸
- [`feasibility_report.md`](feasibility_report.md): AlphaZero/MCTS ì ìš© íƒ€ë‹¹ì„± ë° ë‹¨ê³„ë³„ êµ¬í˜„ ë¡œë“œë§µ
- [`frontend/README.md`](frontend/README.md): í”„ë¡ íŠ¸ì—”ë“œ(Next.js) ì‹¤í–‰/ê°œë°œ ê°€ì´ë“œ

### `docs/` Core Guides

- [`docs/STUDY_GUIDE.md`](docs/STUDY_GUIDE.md): í•™ìŠµ ìˆœì„œ ì¤‘ì‹¬ì˜ ìŠ¤í„°ë”” ê°€ì´ë“œ
- [`docs/IMPLEMENTATION_GUIDE.md`](docs/IMPLEMENTATION_GUIDE.md): ë‹¨ê³„ë³„ êµ¬í˜„ ì ˆì°¨ ê°€ì´ë“œ
- [`docs/FILE_GUIDE.md`](docs/FILE_GUIDE.md): íŒŒì¼/ëª¨ë“ˆ ë‹¨ìœ„ ì—­í•  ì„¤ëª…ì„œ
- [`docs/PROJECT_PRINCIPLES.md`](docs/PROJECT_PRINCIPLES.md): AI ì„¤ê³„ ì² í•™ê³¼ í•µì‹¬ ì›ë¦¬ í•´ì„¤
- [`docs/AI_CODE_DEEP_DIVE.md`](docs/AI_CODE_DEEP_DIVE.md): AI í•µì‹¬ ì½”ë“œ ë¶„ì„ ì¸ë±ìŠ¤
- [`docs/AI_COMPONENTS_AND_IMPLEMENTATION_KR.md`](docs/AI_COMPONENTS_AND_IMPLEMENTATION_KR.md): AI êµ¬ì„±ìš”ì†Œì™€ í˜„ì¬ êµ¬í˜„ ìƒíƒœ(í•œêµ­ì–´)
- [`docs/FINAL_DEVELOPMENT_REPORT_KR.md`](docs/FINAL_DEVELOPMENT_REPORT_KR.md): ìµœì¢… ê°œë°œ ê²°ê³¼ ì •ë¦¬(í•œêµ­ì–´)

### `docs/` Learning Pairs (EN/KR)

| Topic | English | Korean |
|-------|---------|--------|
| Hyperparameter Design | [docs/HYPERPARAMETER_GUIDE.md](docs/HYPERPARAMETER_GUIDE.md) | [docs/HYPERPARAMETER_GUIDE_KR.md](docs/HYPERPARAMETER_GUIDE_KR.md) |
| MCTS Numerical Walkthrough | [docs/MCTS_WALKTHROUGH.md](docs/MCTS_WALKTHROUGH.md) | [docs/MCTS_WALKTHROUGH_KR.md](docs/MCTS_WALKTHROUGH_KR.md) |
| Safety Mechanisms | [docs/SAFETY_MECHANISMS.md](docs/SAFETY_MECHANISMS.md) | [docs/SAFETY_MECHANISMS_KR.md](docs/SAFETY_MECHANISMS_KR.md) |
| Inference Walkthrough | [docs/INFERENCE_WALKTHROUGH.md](docs/INFERENCE_WALKTHROUGH.md) | [docs/INFERENCE_WALKTHROUGH_KR.md](docs/INFERENCE_WALKTHROUGH_KR.md) |
| Glossary | [docs/GLOSSARY.md](docs/GLOSSARY.md) | [docs/GLOSSARY_KR.md](docs/GLOSSARY_KR.md) |

### `docs/models/` Deep Dives

- [`docs/models/01_representation_network.md`](docs/models/01_representation_network.md): Representation Network (`h`) êµ¬ì¡°/ì—­í•  ë¶„ì„
- [`docs/models/02_dynamics_network.md`](docs/models/02_dynamics_network.md): Dynamics Network (`g`) ìƒíƒœì „ì´/ë³´ìƒ ì˜ˆì¸¡ ë¶„ì„
- [`docs/models/03_prediction_network.md`](docs/models/03_prediction_network.md): Prediction Network (`f`) ì •ì±…/ê°€ì¹˜ ì¶œë ¥ ë¶„ì„
- [`docs/models/04_mcts_engine.md`](docs/models/04_mcts_engine.md): MCTS íƒìƒ‰ ì—”ì§„ êµ¬í˜„ ìƒì„¸ ë¶„ì„
- [`docs/models/05_transformer_model.md`](docs/models/05_transformer_model.md): Transformer ëª¨ë“ˆ êµ¬ì¡° ë° ì‚¬ìš© ë°©ì‹ ë¶„ì„

### `docs/reports/` Release Reports

- [`docs/reports/YYYY-MM-DD/release_report_*.md`](docs/reports): ë¦´ë¦¬ì¦ˆ íŒì • ìë™ ìƒì„± ë³´ê³ ì„œ(ì¼ìë³„ í´ë”)
- [`docs/reports/YYYY-MM-DD/data_status_*.md`](docs/reports): ì¼ì¼ í¬ë¡¤ë§ í›„ ì‹¤ì œ ë°ì´í„° íŒŒì¼ ê¸°ì¤€ ìƒíƒœ ë³´ê³ ì„œ(ì¼ìë³„ í´ë”)
- [`docs/reports/latest_data_status.md`](docs/reports/latest_data_status.md): ìµœì‹  ì¼ì¼ ë°ì´í„° ìƒíƒœ ìš”ì•½(ìë™ ê°±ì‹ )
- [`docs/reports/latest_release_report.md`](docs/reports/latest_release_report.md): ìµœì‹  ë¦´ë¦¬ì¦ˆ íŒì • ìš”ì•½(ìë™ ê°±ì‹ )

## ğŸ”„ Roadmap

- **Day 1** (Current): System setup, initial data collection
- **Day 30**: 30-day real-data window secured across raw/dataset â†’ Begin release-ready training flow
- **Day 60+**: Production-ready predictions

## ğŸ› ï¸ Technology Stack

- **AI Framework**: PyTorch (with Apple MPS acceleration)
- **Web Framework**: FastAPI
- **Data Processing**: NumPy, Pandas, scikit-learn
- **Crawling**: Requests, BeautifulSoup4
- **Automation**: Cron

## ğŸ¤– Development Tools & AI Assistance

This project was developed with assistance from multiple AI tools, demonstrating the collaborative future of software development:

- **GLM (GLM-4.7)**: Used for initial architecture design and Korean documentation
- **Antigravity**: Assisted with code generation and feature engineering implementation
- **Claude Code**: Provided development assistance, code review, and documentation refinement
- **Codex**: Provided development assistance, code review, and documentation refinement

**Transparency Note**: As part of the 0.1B AI Project philosophy, I believe in honest disclosure of development tools. This project showcases human-AI collaboration, where AI assists in accelerating development while the core design decisions, architecture, and problem-solving approach remain human-driven.

## ğŸ“Š Model Specifications

- **Total Parameters**: 18.9M
- **Representation Network**: 6.4M params (256D latent state)
- **Dynamics Network**: 6.5M params (state transition + reward)
- **Prediction Network**: 6.0M params (policy + value)
- **MCTS Simulations**: 50 per decision

## ğŸ”§ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/ask` | POST | Get agent decision for GPU model |
| `/api/training/start` | POST | Start AI training |
| `/api/training/stop` | POST | Stop training |
| `/api/training/metrics` | GET | Get training metrics |
| `/api/agent/readiness` | GET | Check 30-day data readiness |
| `/api/agent/evaluate` | GET | Run backtest evaluation |
| `/api/agent/release-check` | GET | Run release quality gates |
| `/api/agent/model-info` | GET | Check loaded model metadata |
| `/api/agent/pipeline/run` | POST | Run full release pipeline (readinessâ†’trainâ†’evaluateâ†’report) |
| `/api/system/status` | GET | System status |
| `/docs` | GET | Swagger UI documentation |

## âœ… One-Click Release (After 30 Days)

When 30-day crawling is complete, run the full release flow from CLI:

```bash
python3 backend/run_release_ready.py
```

Options:

```bash
# Validate gates without forcing 30-day window (for dry run)
python3 backend/run_release_ready.py --allow-short-window --no-train --lookback-days 7

# On pass, create and push release tag
python3 backend/run_release_ready.py --tag --push-tag
```

## ğŸ“ Disclaimer

This project is for **educational and research purposes only**. It uses algorithms inspired by AlphaGo Zero / MuZero (DeepMind) for studying reinforcement learning applications in market analysis. Not intended for commercial use or financial advice.

## ğŸ‘¤ Author

**Jin Younghwa**
Email: timotolkie@gmail.com

Creator of the 0.1B AI Project series, exploring how thoughtful architecture and smart feature engineering can deliver powerful AI solutions without requiring billions of parameters.

## ğŸ¤ Contributing

This is a personal research project. Feel free to fork and experiment!

---

**Last Updated**: 2026-02-21
**Version**: 0.2.0
**Project Type**: 0.1B AI Project
